/**
 * AI 知識溫故知新 - 探索型核心問題
 * 30 條引導式問題，幫助學習者深入理解 AI 核心概念
 * 每個回答包含詳細解釋和具體例子
 */

const explorationQuestions = [
    // ===== 語言理解類 =====
    {
        id: 'eq1',
        category: '語言理解',
        question: '為何 AI 可以讀懂我寫的指令？',
        answer: `AI 能夠理解你的指令，是因為它經過了大規模的語言訓練。具體來說：

〔訓練過程〕
AI 模型（如 GPT、Claude）在訓練時閱讀了互聯網上數十億個網頁、書籍、論文等文本。通過不斷預測「下一個詞應該是什麼」，模型學會了語言的統計規律和語義關係。

〔注意力機制〕
Transformer 架構中的「自注意力」機制讓 AI 能同時關注句子中所有詞彙的關係。例如當你寫「請幫我寫一封給老闆的道歉信」，AI 會同時理解這是「寫作任務」、「郵件格式」、「道歉語氣」、「正式場合」。

〔例子〕
當你輸入「把這段英文翻譯成中文」，AI 能識別這是翻譯任務，而不是寫作或總結，因為「翻譯」這個詞在訓練數據中經常與語言轉換任務一起出現。`,
        keyPoints: ['大型語言模型', '注意力機制', '語義理解', '上下文分析']
    },
    {
        id: 'eq2',
        category: '語言理解',
        question: 'AI 如何學習人類語言？',
        answer: `AI 學習語言分為兩個主要階段：

〔預訓練階段〕
模型閱讀海量文本，學習預測被遮蓋的詞或下一個詞。例如給定「今天天氣很___」，模型學會預測「好」「熱」等合理答案。這讓它掌握了語法、詞彙搭配、甚至常識知識。

〔微調階段（RLHF）〕
人類標註員會評價 AI 的回答質量。好的回答被獎勵，差的被懲罰。這就是「人類反饋強化學習」(RLHF)，讓 AI 學會寫出更有幫助、更安全、更符合人類期望的回答。

〔例子〕
• 預訓練讓 AI 知道「蘋果」可以是水果也可以是公司
• RLHF 教會 AI 當你問「蘋果股價」時，應該回答科技公司而非水果價格
• 如果 AI 生成了有害內容，人類標註員會給負面反饋，AI 學會避免這類輸出`,
        keyPoints: ['預訓練', '微調', 'RLHF', '下一詞預測']
    },
    {
        id: 'eq3',
        category: '語言理解',
        question: '為什麼同樣的問題用不同方式問，AI 的回答會不同？',
        answer: `這是因為 AI 對文字的每一個細節都非常敏感：

〔統計分佈差異〕
不同措辭會激活模型內部不同的「概率路徑」。例如：
• 問「什麼是機器學習？」→ 傾向給出教科書式定義
• 問「用簡單的話解釋機器學習」→ 傾向用比喻和日常語言
• 問「我是5歲小孩，什麼是機器學習？」→ 會用更簡單的詞彙和例子

〔提示工程的重要性〕
這就是為什麼「提示工程」如此重要。好的提示能大幅提升輸出質量。

〔例子〕
✗「幫我寫代碼」→ 可能生成任意語言的任意功能
✓「用 Python 寫一個函數，輸入是用戶年齡，輸出是否成年（18歲以上），包含輸入驗證和錯誤處理」→ 得到精確符合需求的代碼`,
        keyPoints: ['提示敏感性', '輸出分佈', '提示工程', '上下文影響']
    },

    // ===== 自動化操作類 =====
    {
        id: 'eq4',
        category: '自動化操作',
        question: '為何 AI 可以自動化操作電腦實現無人值班工作？',
        answer: `AI 自動化的核心是「AI Agent」架構，它結合了理解、規劃和執行能力：

〔工作原理〕
1. 理解任務：AI 讀懂你的指令（例如「每天早上9點把銷售報表發給經理」）
2. 分解步驟：自動規劃出具體動作序列（打開郵箱→讀取報表→編寫郵件→發送）
3. 調用工具：通過 API 或 RPA 工具實際執行操作
4. 錯誤處理：遇到問題時自動調整策略

〔關鍵技術〕
• 函數調用（Function Calling）：AI 決定何時使用什麼工具
• MCP（Model Context Protocol）：讓 AI 與外部服務通信的標準

〔例子〕
Anthropic 的 Claude Computer Use 能夠：
• 看著屏幕截圖理解當前界面
• 決定點擊哪個按鈕或輸入什麼文字
• 像人類一樣操作網頁、填表、處理文件`,
        keyPoints: ['AI Agent', '工具調用', 'RPA', '任務規劃']
    },
    {
        id: 'eq5',
        category: '自動化操作',
        question: 'AI 如何知道該在網頁上點擊哪個按鈕？',
        answer: `AI 可以通過兩種方式「看懂」網頁界面：

〔視覺理解方式〕
多模態 AI（如 GPT-4V、Claude Vision）可以：
1. 接收網頁截圖
2. 識別圖像中的按鈕、輸入框、文字
3. 計算點擊坐標
4. 就像人類看著屏幕一樣操作

〔結構化方式〕
AI 可以讀取網頁的 HTML/DOM 結構：
1. 解析頁面元素（&lt;button&gt;、&lt;input&gt; 等標籤）
2. 找到目標元素的 CSS 選擇器或 XPath
3. 直接定位並操作

〔例子〕
假設要在購物網站下單：
• 視覺方式：AI 看截圖，發現紅色「立即購買」按鈕在右下角，計算坐標 (850, 620) 點擊
• 結構化方式：AI 讀 HTML，找到 &lt;button id="buy-now"&gt;，直接調用 click() 方法`,
        keyPoints: ['視覺理解', 'DOM 解析', '元素定位', '界面識別']
    },
    {
        id: 'eq6',
        category: '自動化操作',
        question: 'N8N 和 Make 這類工具如何讓 AI 自動化更簡單？',
        answer: `這些是「低代碼/無代碼自動化平台」，讓非程序員也能建立複雜的 AI 工作流：

〔核心優勢〕
1. 可視化編輯：用拖拽方式連接不同步驟，像畫流程圖一樣
2. 預建連接器：已經處理好各種服務的 API 認證（Gmail、Slack、OpenAI 等）
3. 錯誤處理：內建重試機制、錯誤通知
4. 無需編程：不用寫代碼就能建立自動化流程

〔與 AI 結合〕
• 在流程中插入 AI 節點（如 OpenAI、Claude）
• AI 處理需要「判斷」的步驟

〔例子〕
客服自動回覆流程：
1. 觸發器：收到新郵件
2. AI 節點：分析郵件內容，判斷是「訂單查詢」還是「退款申請」還是「技術問題」
3. 條件分支：根據分類執行不同動作
4. 若是訂單查詢 → 調用訂單系統 API 獲取狀態 → AI 生成回覆 → 發送郵件`,
        keyPoints: ['低代碼平台', '工作流自動化', 'API 整合', '視覺化編程']
    },

    // ===== 視覺能力類 =====
    {
        id: 'eq7',
        category: '視覺能力',
        question: '為何 AI 能按我要求修改或創造要求的圖片？',
        answer: `圖像生成 AI（如 Midjourney、DALL-E、Stable Diffusion）使用「擴散模型」技術：

〔擴散模型原理〕
1. 訓練時：模型學習如何給圖片逐步加噪聲（清晰圖→雜訊圖），然後反向學習如何去噪
2. 生成時：從純噪聲開始，逐步去噪還原成圖片，但這次按照你的文字描述來「引導」去噪方向

〔文字如何控制圖像〕
• CLIP 模型預先學習了「圖像-文字配對」
• 當你寫「一隻戴帽子的貓」，CLIP 把這句話編碼成向量
• 擴散過程中，每一步都檢查當前圖像是否符合這個向量，不斷調整

〔例子〕
輸入：「賽博朋克風格的香港夜景，霓虹燈，雨天，高清」
AI 理解每個關鍵詞：賽博朋克（藍紫色調、科技感）、香港（高樓密集）、霓虹燈（招牌）、雨天（倒影、濕潤質感）
去噪過程中確保這些元素都呈現在最終圖像中`,
        keyPoints: ['擴散模型', '文生圖', '圖像編輯', 'CLIP 文本編碼']
    },
    {
        id: 'eq8',
        category: '視覺能力',
        question: '為何 AI 可以看見環境或電腦畫面並作出正確判斷？',
        answer: `多模態 AI 可以同時處理圖像和文字，實現「視覺理解」：

〔技術原理〕
1. 視覺編碼器：將圖像切成小塊（patch），轉換成數字向量
2. 跨模態對齊：訓練時讓「貓的圖片」和「貓這個詞」在向量空間中靠近
3. 統一處理：圖像向量和文字向量一起輸入模型，模型能理解兩者關係

〔能做什麼〕
• 描述圖片內容
• 回答關於圖片的問題
• 讀取圖中文字（OCR）
• 理解圖表、界面截圖

〔例子〕
給 AI 一張報表截圖問「這個月銷售最好的產品是什麼？」
1. AI 識別這是一個表格
2. 找到「銷售額」欄位
3. 比較數值大小
4. 返回「手機殼，銷售額 52,000 元」

另一個例子：把手寫筆記拍照給 AI，它能識別手寫字，整理成電子文檔`,
        keyPoints: ['多模態模型', '視覺編碼', '視覺推理', '圖文對齊']
    },
    {
        id: 'eq9',
        category: '視覺能力',
        question: 'AI 如何辨認圖片中的物體和文字？',
        answer: `物體識別和文字識別用不同的專門技術：

〔物體識別（Object Detection）〕
• 使用 CNN 或 Vision Transformer 提取圖像特徵
• 模型學會識別「邊緣→形狀→部件→整體物體」的層級結構
• 例如：識別「貓」= 看到尖耳朵 + 鬍鬚 + 毛皮紋理 + 貓臉輪廓

〔文字識別（OCR）〕
1. 文字檢測：找出圖中哪裡有文字（框出文字區域）
2. 文字識別：逐字識別每個字符
3. 後處理：糾正錯誤，整合成完整文本

〔現代多模態模型的優勢〕
GPT-4V、Claude Vision 等大模型不需要單獨的 OCR，視覺理解能力是端到端學習的。

〔例子〕
• 傳統 OCR：專門訓練來認字，可能把「0」誤認為「O」
• 多模態 AI：理解整個上下文，知道在價格表裡「O」更可能是「0」，在人名裡「0」更可能是「O」`,
        keyPoints: ['CNN', 'Vision Transformer', 'OCR', '特徵提取']
    },

    // ===== AI 局限性類 =====
    {
        id: 'eq10',
        category: 'AI 局限性',
        question: '為何 AI 有時也會做錯看似簡單的工作？',
        answer: `AI 的「簡單」和人類的「簡單」完全不同，這源於它的工作原理：

〔根本原因：AI 是「概率預測」不是「邏輯計算」〕
• AI 通過預測下一個最可能的詞來生成回答
• 它沒有真正的「思考」或「計算」能力
• 數學、邏輯、計數這些需要精確計算的任務，對 AI 來說反而困難

〔常見「翻車」場景〕
1. 數學計算：問「123×456=?」，AI 可能算錯（因為它在「猜」答案）
2. 字數控制：要求寫 200 字，結果寫了 500 字
3. 計數問題：問「strawberry 裡有幾個 r？」可能答錯

〔為什麼會這樣？〕
• 訓練數據中計算題的答案是「記住」的，不是「算出來」的
• 當遇到訓練數據沒見過的數字組合，就容易出錯

〔例子〕
• AI 能寫出感人的情詩（語言模式匹配）
• 但 AI 數「banana有幾個字母」可能答錯（需要精確計數）
• 解決方案：讓 AI 調用計算器工具，把計算任務交給專門的程序`,
        keyPoints: ['幻覺問題', '分佈外泛化', '計算限制', '訓練數據偏差']
    },
    {
        id: 'eq11',
        category: 'AI 局限性',
        question: 'AI 的「幻覺」問題是怎麼產生的？',
        answer: `「幻覺」(Hallucination) 是指 AI 一本正經地說出不存在的事實：

〔產生原因〕
1. 統計本質：AI 生成「看起來合理」的內容，而非「真正正確」的內容
2. 過度自信：模型沒有「我不知道」的概念，會編造答案填補空白
3. 訓練數據偏差：錯誤信息也被學習進去了

〔典型幻覺類型〕
• 捏造不存在的學術論文和作者
• 編造歷史事件的細節
• 產生看似合理但錯誤的技術解釋
• 說出不存在的法律條文或統計數據

〔例子〕
問 AI：「張三寫的《人工智能的未來》這本書摘要是什麼？」
即使這本書不存在，AI 可能會回答：「《人工智能的未來》由著名學者張三於2020年出版，討論了AI的倫理問題...」
AI 根據書名、作者名的模式「想像」出合理的內容

〔如何減少幻覺〕
• 使用 RAG（檢索增強生成）讓 AI 基於真實資料回答
• 讓 AI 引用來源
• 鼓勵 AI 在不確定時說「我不確定」`,
        keyPoints: ['統計生成', '過度自信', '事實核查', '知識截止']
    },
    {
        id: 'eq12',
        category: 'AI 局限性',
        question: '為什麼 AI 有知識截止日期的限制？',
        answer: `AI 模型的知識是在訓練時「凍結」的，之後的新信息它一無所知：

〔原因解析〕
• 訓練需要數月和數百萬美元成本
• 訓練完成後，模型參數固定
• 新聞、科學發現、時事變化都無法自動更新

〔知識截止的影響〕
• 問2024年發生的事，2023年訓練的模型會說不知道
• 可能給出過時的信息（舊版本軟件教程、已廢除的法規）

〔解決方案〕
1. RAG（檢索增強生成）：AI 回答前先搜索最新資料
2. 實時搜索整合：連接搜索引擎獲取即時信息
3. 定期重新訓練：更新模型但成本高昂

〔例子〕
• 問 GPT-3.5（2021年訓練）：「誰是美國總統？」→ 可能答拜登或特朗普
• 問整合了搜索的 AI：會先搜索再回答當前總統
• 最佳實踐：對時效性強的問題，讓 AI 先搜索再回答`,
        keyPoints: ['知識截止', 'RAG', '即時搜索', '模型更新']
    },

    // ===== 推理思考類 =====
    {
        id: 'eq13',
        category: '推理思考',
        question: '為何 AI 可以做到擬人的深度思考和推理？',
        answer: `現代 AI 的推理能力來自特殊的訓練技術和架構設計：

〔思維鏈（Chain-of-Thought）〕
• 訓練 AI 逐步展示推理過程，而非直接跳到答案
• 「先想再答」比「直接答」準確率大幅提升

〔推理專用模型（如 o1）〕
• 專門訓練來進行多步驟邏輯推導
• 會自動分解複雜問題，逐個解決
• 在數學、編程、科學問題上表現突出

〔例子〕
問題：「籃子裡有5個蘋果，小明拿走2個，然後媽媽放入3個，籃子裡有幾個蘋果？」

普通回答：6個（可能錯誤）

思維鏈回答：
1. 初始狀態：5個蘋果
2. 小明拿走2個：5 - 2 = 3個
3. 媽媽放入3個：3 + 3 = 6個
4. 答案：6個蘋果

後者不僅答案對，過程也可驗證，減少了錯誤並增加了可信度。`,
        keyPoints: ['思維鏈', 'o1 推理模型', '多步推理', '問題分解']
    },
    {
        id: 'eq14',
        category: '推理思考',
        question: 'AI 真的在「思考」嗎？還是只是模式匹配？',
        answer: `這是 AI 領域最具爭議的哲學問題之一：

〔技術層面的事實〕
• AI 確實只是在進行超大規模的「模式匹配」和「統計推斷」
• 它沒有意識、感受、意圖
• 所有「思考」都是數學運算

〔為什麼看起來像思考〕
• 模式足夠複雜時，表現出來就像「理解」
• 能處理從未見過的新問題（泛化能力）
• 能進行多步推理和類比

〔哲學爭議〕
• 「功能主義」觀點：能模擬思考就等於思考
• 「中文房間」論證：即使完美模擬，也不是真正理解
• 目前無法用科學方法證明任何一方

〔例子〕
計算器能算 987654321 × 123456789，但我們不說它「理解」數學
AI 能寫詩、講故事、解決問題，但這是「理解」還是「模式匹配」？
答案取決於你如何定義「理解」和「思考」`,
        keyPoints: ['模式匹配', '統計推斷', '意識問題', 'AI 哲學']
    },
    {
        id: 'eq15',
        category: '推理思考',
        question: '為什麼讓 AI 一步步思考能得到更好的答案？',
        answer: `這被稱為「思維鏈提示」(Chain-of-Thought Prompting)，效果顯著的原因：

〔計算資源分配〕
• 直接回答時，AI 只有一次機會生成答案
• 逐步思考時，每一步都分配了計算資源
• 中間步驟可以自我校正

〔類比人類〕
• 心算 17×24 容易出錯
• 筆算寫下每一步，準確率大增
• AI 也是類似道理

〔研究發現〕
• 對於複雜數學問題，思維鏈提示可將準確率從 20% 提升到 80%
• 對於簡單問題，差異不大
• 問題越複雜，思維鏈越有價值

〔例子〕
問題：「一輛車2小時開了120公里，然後休息1小時，接著3小時開了180公里，平均時速是多少？」

✗ 直接回答：「60公里/小時」（錯誤，忘了休息時間）

✓ 思維鏈回答：
1. 總距離：120 + 180 = 300公里
2. 總時間：2 + 1 + 3 = 6小時（包含休息）
3. 行駛時間：2 + 3 = 5小時（不含休息）
4. 如果問的是「行駛平均速度」：300 ÷ 5 = 60公里/小時
5. 如果問的是「全程平均速度」：300 ÷ 6 = 50公里/小時
6. 需要澄清問題定義`,
        keyPoints: ['推理步驟', '計算分配', '錯誤減少', '過程監督']
    },

    // ===== 人機關係類 =====
    {
        id: 'eq16',
        category: '人機關係',
        question: '有什麼是 AI 永遠無法取替人類的？',
        answer: `儘管 AI 能力驚人，某些領域可能始終需要人類：

〔1. 真正的情感連結〕
• AI 可以模擬關懷，但無法真正感受
• 朋友安慰你時的「我理解你的感受」和 AI 說的完全不同
• 人際關係的價值在於雙向的情感交流

〔2. 道德責任承擔〕
• AI 做錯了，誰負責？是用戶、開發者還是 AI？
• 法官判案、醫生最終診斷、高風險決策需要人類負責
• 社會需要有人為決定承擔後果

〔3. 身體經驗〕
• 美食的滋味、擁抱的溫暖、運動的快感
• AI 可以描述，但不能體驗
• 很多創作靈感來自「活著」的感受

〔4. 原創vs.重組〕
• AI 的「創作」是對已有內容的重組
• 真正開創性的突破——愛因斯坦的相對論、畢加索的立體主義——來自人類的直覺跳躍

〔例子〕
• 心理諮詢師可能用 AI 輔助記錄，但來訪者需要的是「被另一個人類理解」
• 法官可以用 AI 分析案例，但判決的責任必須由人類承擔`,
        keyPoints: ['情感連結', '道德責任', '意識', '身體經驗']
    },
    {
        id: 'eq17',
        category: '人機關係',
        question: 'AI 會搶走我的工作嗎？',
        answer: `更準確的說法是「AI 會改變工作方式」而非「取代工作」：

〔歷史規律〕
• 工業革命：機器取代了手工生產，但創造了更多工廠工人崗位
• 電腦革命：取代了打字員，但創造了程序員、網頁設計師等新職業
• AI 革命：模式可能類似

〔AI 對工作的影響光譜〕
1. 高風險：高度重複、可標準化的任務（數據輸入、簡單翻譯）
2. 會改變：需要創意但可借助 AI 提效（寫作、設計、編程）
3. 低風險：需要人際互動、複雜判斷、身體技能（護理、心理諮詢、水電工）

〔關鍵策略〕
• 學會使用 AI 工具成為核心競爭力
• 專注「AI 做不好」的能力：溝通、領導、創意思維
• 持續學習，適應變化

〔例子〕
• 以前：律師助理花大量時間搜索案例
• 現在：AI 可以秒速搜索，助理轉而專注分析和策略
• 未來：不會用 AI 的律師可能被會用 AI 的律師取代`,
        keyPoints: ['工作轉型', 'AI 協作', '技能升級', '自動化趨勢']
    },
    {
        id: 'eq18',
        category: '人機關係',
        question: '如何判斷什麼任務適合交給 AI？',
        answer: `一個簡單的評估框架幫你決定是否使用 AI：

〔適合 AI 的任務〕（越多「是」越適合）
✓ 重複性高？（每天做類似的事）
✓ 有明確標準？（對錯可以判斷）
✓ 容錯空間大？（錯了可以改）
✓ 需要處理大量信息？
✓ 現有工具可以完成？

〔不適合 AI 的任務〕（有任一項就要謹慎）
✗ 需要情感共鳴？（安慰朋友）
✗ 高風險決策？（醫療診斷、法律判決）
✗ 需要創意原創？（全新藝術風格）
✗ 涉及敏感數據？（客戶隱私）
✗ 需要實時更新信息？

〔例子〕
任務              是否適合AI    原因
寫週報            ✓            重複性高，可審核
分析銷售數據      ✓            大量信息處理
安慰失戀朋友      ✗            需要情感連結
醫療最終診斷      ✗            高風險，需負責
頭腦風暴          ✓            生成想法，人類篩選
核實新聞真假      ⚠️           AI可協助，但需人類判斷`,
        keyPoints: ['任務評估', '風險考量', '效率對比', '人機分工']
    },

    // ===== 模型差異類 =====
    {
        id: 'eq19',
        category: '模型差異',
        question: '為何不同 AI 模型表現差異如此大？',
        answer: `看似相似的 AI 模型，表現可能天差地別，原因包括：

〔1. 訓練數據〕
• 數據量：從數十億到數萬億token不等
• 數據質量：網頁垃圾 vs 精選書籍論文
• 例子：用維基百科訓練的模型比用論壇帖子訓練的更準確

〔2. 模型架構〕
• 參數規模：從10億到1萬億參數
• 架構設計：不同的注意力機制設計
• 例子：GPT-4 參數量可能是 GPT-3 的10倍

〔3. 訓練方法〕
• 對齊策略：如何教模型「什麼是好回答」
• RLHF 資源：人類標註的數量和質量
• 例子：同樣基礎模型，經過不同 RLHF 後行為大不同

〔4. 特定優化〕
• 針對代碼、數學、多語言等特定領域加強訓練
• 例子：Claude 對長文本處理特別優化

〔直觀比喻〕
• 訓練數據 = 學生讀的書
• 模型架構 = 學生的大腦容量
• 訓練方法 = 老師的教學方式
• 同一本教材，不同老師教出的學生水平也不同`,
        keyPoints: ['訓練數據', '模型架構', '參數規模', '對齊策略']
    },
    {
        id: 'eq20',
        category: '模型差異',
        question: 'Claude、GPT、Gemini 有什麼核心區別？',
        answer: `三大主流模型各有特色和側重：

〔OpenAI GPT 系列〕
• 特點：最早的主流大模型，生態系統最完善
• 強項：通用能力強，API 成熟，插件豐富
• 定位：「全能型選手」
• 例子：ChatGPT Plus 結合 DALL-E（圖像）、代碼解釋器（數據分析）

〔Anthropic Claude〕
• 特點：強調安全性和有幫助的對話
• 強項：超長上下文（200K token）、降低幻覺、誠實承認不確定性
• 定位：「可靠的助手」
• 例子：可以一次處理一整本 50 頁的 PDF 文件

〔Google Gemini〕
• 特點：與 Google 服務深度整合
• 強項：實時搜索、多模態理解、整合 Google 生態
• 定位：「整合型助手」
• 例子：可以直接搜索最新信息，整合 Gmail、Drive

〔選擇建議〕
需求                推薦
處理超長文檔        Claude
需要最新信息        Gemini
豐富的插件/工具     ChatGPT
代碼生成            三者都不錯
最在意安全性        Claude`,
        keyPoints: ['模型特色', '安全設計', '生態系統', '使用場景']
    },
    {
        id: 'eq21',
        category: '模型差異',
        question: '開源模型和閉源模型有什麼優劣？',
        answer: `開源（Llama、Mistral）vs 閉源（GPT-4、Claude）各有取捨：

〔開源模型優勢〕
• 成本可控：本地運行無 API 費用
• 隱私保護：數據不離開你的服務器
• 可定制：可以微調適應特定任務
• 透明度：可以知道模型如何工作

〔開源模型劣勢〕
• 需要 GPU 硬件和技術人員
• 性能通常不如頂級閉源模型
• 需要自己處理安全對齊

〔閉源模型優勢〕
• 開箱即用：無需任何配置
• 性能最強：通常是最先進的模型
• 持續更新：自動獲得改進
• 安全對齊：已做好護欄

〔閉源模型劣勢〕
• API 費用可能很高
• 數據發送到第三方服務器
• 無法精細控制

〔選擇建議〕
場景                選擇
創業公司初期        閉源（快速驗證想法）
處理敏感數據        開源（本地部署）
預算有限            開源（無API費用）
需要最強性能        閉源（GPT-4、Claude）
特定領域應用        開源（可微調）`,
        keyPoints: ['開源 vs 閉源', '本地部署', '成本對比', '隱私考量']
    },

    // ===== 技術原理類 =====
    {
        id: 'eq22',
        category: '技術原理',
        question: 'Transformer 架構為何能讓 AI 如此強大？',
        answer: `2017年 Google 發明的 Transformer 架構是現代 AI 的基石：

〔核心創新：自注意力機制（Self-Attention）〕
• 傳統方法（RNN）：逐詞處理，像閱讀時一個字一個字看
• Transformer：同時關注所有詞，像掃描整個句子再理解
• 優勢：能捕捉任意距離的詞之間的關係

〔為什麼這很重要？〕
句子：「小明把書借給了小華，他很高興」
• 「他」指的是誰？需要理解整個句子的語境
• 自注意力讓模型計算「他」和其他每個詞的關係強度
• 從而判斷「他」更可能指「小華」（因為是收到書的人）

〔並行計算優勢〕
• RNN 必須順序處理，無法利用 GPU 並行
• Transformer 可以同時處理所有位置，訓練速度快數十倍
• 這讓訓練超大模型成為可能

〔例子〕
翻譯「The animal didn't cross the street because it was too tired」
• 「it」指什麼？需要注意力機制連接「it」和「animal」
• 如果是「too wide」，「it」就指「street」
• 模型通過注意力權重自動學會這種推理`,
        keyPoints: ['自注意力', '並行計算', '長距離依賴', '上下文建模']
    },
    {
        id: 'eq23',
        category: '技術原理',
        question: '什麼是 Token？為何 AI 按 Token 收費？',
        answer: `Token 是 AI 處理文本的基本單位，理解它對控制成本很重要：

〔Token 是什麼？〕
• 不是字符，不是單詞，而是介於兩者之間
• 大約：1 token ≈ 0.75 個英文單詞 ≈ 1-2 個中文字
• 例如：「Hello world」= 2 tokens；「你好世界」≈ 4 tokens

〔為什麼按 Token 收費？〕
• AI 的計算成本與處理的 token 數量直接相關
• 每個 token 都需要通過整個神經網絡的計算
• Token 越多，計算量越大，成本越高

〔Token 的計算方式〕
內容                        大約 Token 數
一封短郵件（100字）         ~50 tokens
一頁 A4 文字                ~500 tokens
一本書（10萬字）            ~50,000 tokens
GPT-4 一次對話上限          8,192-128,000 tokens

〔省錢技巧〕
• 精簡提示語，避免冗餘
• 避免讓 AI 重複輸出長內容
• 使用更便宜的模型處理簡單任務

〔例子〕
• 輸入1000個 token + 輸出2000個 token = 按3000 token 收費
• GPT-4 Turbo 約 $0.01/1K input tokens + $0.03/1K output tokens
• 處理一本10萬字的書可能需要 $1-5`,
        keyPoints: ['Token 定義', 'Token 計算', '成本結構', '上下文長度']
    },
    {
        id: 'eq24',
        category: '技術原理',
        question: 'AI 的「上下文長度」限制意味著什麼？',
        answer: `上下文長度是 AI 一次能「記住」的信息量限制：

〔什麼是上下文長度？〕
• 模型一次能處理的最大 token 數
• 包括：你的輸入 + AI 的回覆 + 對話歷史
• 超出限制的內容會被「遺忘」

〔不同模型的上下文長度〕
模型          上下文長度              相當於
GPT-3.5       4,096 tokens           ~6頁
GPT-4         8,192-128,000 tokens   ~200頁
Claude 3      200,000 tokens         ~一本書
Gemini 1.5    1,000,000 tokens       ~多本書

〔超出上下文的後果〕
• 早期對話會被截斷或遺忘
• AI 可能「忘記」之前說過的話
• 長文檔需要分段處理

〔實際影響〕
• 處理長合同、長論文需要足夠的上下文
• 多輪對話會逐步填滿上下文空間
• 超出後可能出現「健忘」現象

〔例子〕
你和 AI 討論一個複雜項目，聊了很多輪：
• 如果超出上下文：AI 可能忘記第一輪你說的項目名稱
• 解決方案：定期總結對話要點，或使用長上下文模型`,
        keyPoints: ['上下文限制', 'Token 上限', '長文本處理', '記憶機制']
    },

    // ===== 實際應用類 =====
    {
        id: 'eq25',
        category: '實際應用',
        question: 'AI 如何幫助我提高工作效率？',
        answer: `AI 可以在多個工作場景大幅提升效率，關鍵是找對應用場景：

〔高價值應用場景〕

〔1. 寫作與文檔〕
• 起草郵件、報告、提案（從30分鐘→5分鐘）
• 潤色和改寫文字（提升專業度）
• 例子：「幫我把這段技術說明改寫成給非技術人員看的版本」

〔2. 數據處理〕
• 整理混亂的數據
• 生成Excel公式
• 例子：「把這100條客戶反饋分類成正面、負面、建議三類」

〔3. 編程輔助〕
• 生成代碼片段
• 解釋和調試錯誤
• 例子：「寫一個Python函數，讀取CSV文件並計算每列平均值」

〔4. 學習與研究〕
• 解釋複雜概念
• 總結長文檔
• 例子：「用簡單語言解釋這篇論文的核心觀點」

〔5. 創意發想〕
• 頭腦風暴想法
• 打破思維定勢
• 例子：「給我10個推廣新產品的創意營銷方案」

〔效率提升的關鍵〕
• 識別重複性工作
• 建立個人的提示模板
• 先讓 AI 生成草稿，你來修改完善`,
        keyPoints: ['效率提升', '工作流自動化', '常見應用', '任務識別']
    },
    {
        id: 'eq26',
        category: '實際應用',
        question: '為什麼我需要學習「提示工程」？',
        answer: `提示工程（Prompt Engineering）是與 AI 高效溝通的技術，直接影響輸出質量：

〔為什麼重要？〕
同樣的模型，好提示和差提示的輸出質量可能相差10倍。
提示是你和 AI 之間的「接口」，學會使用它事半功倍。

〔核心提示技巧〕

〔1. 明確角色〕
• ✗「寫一篇文章」
• ✓「你是一位資深財經記者，為《經濟日報》寫一篇關於...」

〔2. 提供範例（Few-shot）〕
• ✗「翻譯成正式中文」
• ✓「翻譯成正式中文，參考這個風格：[提供例子]」

〔3. 拆分步驟〕
• ✗「幫我分析這個問題並給出解決方案」
• ✓「第一步，列出問題的可能原因；第二步，評估每個原因的可能性；第三步，為最可能的原因提出解決方案」

〔4. 設定限制〕
• ✗「寫一個產品介紹」
• ✓「用3段話介紹產品，每段不超過50字，重點突出價格優勢」

〔例子〕
任務：寫一封請假郵件
• 差：「幫我寫請假信」→ 生成模糊的通用內容
• 好：「我是市場部員工，需要請假3天（下週一到週三）參加家人婚禮。我的經理是王總，公司文化比較正式。請幫我寫一封請假郵件，語氣專業禮貌，包含請假原因、時間、工作交接安排。」`,
        keyPoints: ['提示技巧', '輸出質量', '角色設定', '範例提供']
    },
    {
        id: 'eq27',
        category: '實際應用',
        question: 'RAG 是什麼？為何它能讓 AI 回答更準確？',
        answer: `RAG（Retrieval-Augmented Generation，檢索增強生成）是讓 AI 基於真實資料回答的技術：

〔核心原理〕
1. 建立知識庫：把你的文檔、資料庫內容向量化存儲
2. 檢索階段：用戶提問時，先搜索最相關的文檔片段
3. 生成階段：把檢索到的內容連同問題一起給 AI，讓它基於這些資料回答

〔為什麼更準確？〕
• AI 不再靠「記憶」回答，而是基於「證據」回答
• 可以處理私有數據（公司內部文件）
• 解決知識截止問題（可以導入最新資料）

〔架構示意〕
用戶問題 → 向量搜索 → 找到相關文檔段落 → AI 基於文檔生成回答

〔例子〕
場景：公司內部 AI 助手

用戶問：「我們公司的年假政策是什麼？」

沒有 RAG：
• AI 只能給出通用的年假建議
• 可能編造不存在的政策

有 RAG：
1. 系統搜索公司HR文檔
2. 找到「員工手冊第5章：休假政策」
3. AI 回答：「根據公司政策，入職滿一年員工享有15天帶薪年假，每年12月31日前必須休完，不可跨年累積。」
4. 並可附上來源文檔鏈接`,
        keyPoints: ['RAG 原理', '知識庫', '實時檢索', '準確性提升']
    },

    // ===== 未來發展類 =====
    {
        id: 'eq28',
        category: '未來發展',
        question: 'AGI（通用人工智能）真的會實現嗎？',
        answer: `AGI 是 AI 領域的「聖杯」，但何時（甚至是否）能實現仍有很大爭議：

〔什麼是 AGI？〕
• 能夠像人類一樣處理任何智力任務的 AI
• 可以學習任何新技能，不限於特定領域
• 具備泛化能力、常識推理、創造力

〔目前 AI 是「狹義 AI」〕
• 專門訓練的特定任務上超越人類（下棋、圖像識別）
• 但換一個任務就需要重新訓練
• 缺乏真正的「理解」和「遷移學習」

〔專家觀點分歧很大〕
觀點        代表人物               預測時間
樂觀派      Sam Altman（OpenAI）   5-10年
中間派      許多AI研究者           20-50年
悲觀派      Gary Marcus            可能需要全新方法
懷疑派      部分學者               可能永遠不會

〔挑戰〕
• 常識推理：人類天生具備，AI仍困難
• 因果理解：AI 善於相關性，不善於因果
• 持續學習：人類可以終身學習，AI需要重新訓練

〔例子〕
今天的 AI 可以：寫詩、編程、下棋、創作音樂
今天的 AI 不能：理解3歲小孩能理解的物理常識（杯子裡的水倒掉了就沒有了）`,
        keyPoints: ['AGI 定義', '發展預測', '狹義 vs 通用', '能力邊界']
    },
    {
        id: 'eq29',
        category: '未來發展',
        question: 'AI 安全為何是重要議題？',
        answer: `AI 安全不是科幻電影的杞人憂天，而是當下需要解決的現實問題：

〔短期風險（已在發生）〕

〔1. 虛假信息〕
• Deepfake 視頻偽造名人、政客言論
• AI 生成假新聞可大規模傳播
• 例子：2024年選舉中已出現AI偽造的政客通話錄音

〔2. 偏見放大〕
• AI 學習歷史數據中的偏見
• 可能導致招聘、貸款審批中的歧視
• 例子：某公司 AI 招聘系統對女性簡歷評分較低

〔3. 惡意使用〕
• 自動化網絡攻擊
• 更具說服力的釣魚郵件
• 例子：AI 可以模仿你朋友的寫作風格騙取信息

〔長期風險（研究中）〕

〔對齊問題〕
• 如何確保 AI 做我們真正想要的事，而非字面意思？
• 「幫我賺最多錢」→ AI 是否會選擇違法手段？

〔控制問題〕
• 隨著 AI 變得更強大，人類還能保持控制嗎？

〔正在進行的安全措施〕
• Constitutional AI：讓 AI 自我審查
• 紅隊測試：主動尋找漏洞
• 殺死開關：緊急關閉機制
• 可解釋性研究：理解 AI 決策過程`,
        keyPoints: ['AI 安全', '對齊問題', '濫用風險', '價值觀對齊']
    },
    {
        id: 'eq30',
        category: '未來發展',
        question: '普通人如何跟上 AI 發展的步伐？',
        answer: `AI 變化極快，但普通人不需要成為專家，只需要持續「保持接觸」：

〔實用策略〕

〔1. 動手嘗試（最重要）〕
• 註冊使用 ChatGPT、Claude、Gemini
• 用 AI 解決你真正的日常問題
• 不要光看新聞，要親自體驗
• 例子：下次寫郵件時，先讓 AI 起草，你來修改

〔2. 理解原理而非細節〕
• 不需要懂數學公式
• 理解「AI 是統計模型」「它預測下一個詞」這類概念
• 知道優勢和局限

〔3. 關注可靠信息源〕
• 推薦：AI 相關 YouTube 頻道、Podcast
• 主流科技媒體的 AI 版塊
• 避免：誇張標題、販賣焦慮的內容

〔4. 從自己的領域切入〕
• 你是會計？學 AI 如何輔助財務分析
• 你是老師？學 AI 輔助教學
• 不需要學所有東西，專注你的應用場景

〔5. 建立學習社群〕
• 和同行交流 AI 使用經驗
• 分享好用的提示技巧
• 一起解決遇到的問題

〔不要有的心態〕
• ✗「太複雜了，等它成熟再學」
• ✗「AI 會取代我，學了也沒用」
• ✓「先用起來，邊學邊用，逐步精進」

〔例子〕
一年後，你可能：
• 每天用 AI 處理郵件、寫文檔
• 建立了自己的提示詞庫
• 知道什麼問題適合問 AI、什麼需要自己判斷
• 成為團隊裡的「AI 達人」被同事請教`,
        keyPoints: ['持續學習', '實踐操作', '社群參與', '善用工具']
    }
];

// 按分類分組
function getExplorationByCategory() {
    const grouped = {};
    explorationQuestions.forEach(q => {
        if (!grouped[q.category]) {
            grouped[q.category] = [];
        }
        grouped[q.category].push(q);
    });
    return grouped;
}

// 導出
if (typeof window !== 'undefined') {
    window.explorationQuestions = explorationQuestions;
    window.getExplorationByCategory = getExplorationByCategory;
}
